# SignBridge - Sign Language Interpreter

**Real-time sign language to text & speech interpretation using Deep Learning**

Based on: https://github.com/harshbg/Sign-Language-Interpreter-using-Deep-Learning

![Python](https://img.shields.io/badge/Python-3.8+-blue)
![TensorFlow](https://img.shields.io/badge/TensorFlow-2.15-orange)
![FastAPI](https://img.shields.io/badge/FastAPI-0.109-green)

## ğŸ¯ What This Does

This web application interprets American Sign Language (ASL) gestures in real-time:
1. **Captures** gestures via webcam
2. **Recognizes** letters, numbers, and common words using a trained CNN
3. **Builds sentences** from continuous gesture recognition
4. **Speaks** the interpreted sentence using text-to-speech

## ğŸš€ Quick Start

### Prerequisites
- Python 3.8+
- Modern web browser with camera access

### 1. Install Dependencies

```bash
cd python-backend
pip install -r requirements.txt
```

### 2. Start Backend Server

```bash
# Windows
python server.py

# Or double-click START_BACKEND.bat
```

Server starts at: http://localhost:8000

### 3. Open Frontend

**Option A: XAMPP**
```
Place folder in xampp/htdocs/
Visit: http://localhost/SignLanguage/
```

**Option B: Python HTTP Server**
```bash
python -m http.server 8080
# Visit: http://localhost:8080
```

**Option C: Direct**
```
Open recognition.html in browser
```

### 4. Start Interpreting!

1. Click "Start Interpreter"
2. Allow camera access
3. Make sign language gestures
4. Watch sentences build in real-time!

## ğŸ“Š Supported Gestures (44 Classes)

| Type | Gestures |
|------|----------|
| Letters | A, B, C, D, E, F, G, H, I, J, K, L, M, N, O, P, Q, R, S, T, U, V, W, X, Y, Z |
| Numbers | 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 |
| Words | Hello, Thank You, I Love You, Yes, No, Please, Sorry, Help |

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   BROWSER (HTML/JS)                          â”‚
â”‚  - Camera capture via getUserMedia                          â”‚
â”‚  - Sends frames every 200ms                                  â”‚
â”‚  - Displays predictions & builds sentences                   â”‚
â”‚  - Text-to-speech output                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚ HTTP POST /predict-and-build
                         â”‚ FormData: {file: blob, language: ASL}
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PYTHON BACKEND (FastAPI)                        â”‚
â”‚  - Image preprocessing (histogram backprojection)           â”‚
â”‚  - Hand segmentation & contour detection                    â”‚
â”‚  - CNN model prediction (TensorFlow/Keras)                  â”‚
â”‚  - Sentence builder (accumulates characters)                â”‚
â”‚  - Returns: {label, confidence, sentence}                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
SignLanguage/
â”œâ”€â”€ index.html                    # Homepage
â”œâ”€â”€ recognition.html              # Main interpreter UI
â”œâ”€â”€ learning.html                 # Learning resources
â”œâ”€â”€ about.html                    # About page
â”œâ”€â”€ START_BACKEND.bat             # Windows launcher
â”œâ”€â”€ python-backend/
â”‚   â”œâ”€â”€ server.py                 # FastAPI server (main logic)
â”‚   â”œâ”€â”€ requirements.txt          # Python dependencies
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ cnn_model_keras2.h5   # Trained model (add this)
â”‚   â”‚   â””â”€â”€ hist                  # Hand histogram (optional)
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ css/
â”‚   â””â”€â”€ style.css
â”œâ”€â”€ js/
â”‚   â””â”€â”€ recognition.js            # Frontend recognition logic
â””â”€â”€ README.md
```

## ğŸ§  The CNN Model

The recognition uses a Convolutional Neural Network trained on ASL gestures:

**Architecture:**
```
Input: 50x50x1 (grayscale)
  â†“
Conv2D(16, 2x2) â†’ MaxPool(2x2)
  â†“
Conv2D(32, 3x3) â†’ MaxPool(3x3)
  â†“
Conv2D(64, 5x5) â†’ MaxPool(5x5)
  â†“
Flatten â†’ Dense(128) â†’ Dropout(0.2)
  â†“
Output: Softmax(44 classes) â†’ >95% accuracy
```

**To use a trained model:**

1. Train using the original repository's scripts:
   ```bash
   git clone https://github.com/harshbg/Sign-Language-Interpreter-using-Deep-Learning.git
   cd Sign-Language-Interpreter-using-Deep-Learning/Code
   python set_hand_histogram.py
   python create_gestures.py
   python load_images.py
   python cnn_model_train.py
   ```

2. Copy trained files to `python-backend/models/`:
   - `cnn_model_keras2.h5`
   - `hist` (optional)

## ğŸ”Œ API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/` | GET | Server status |
| `/health` | GET | Health check with model info |
| `/predict-image` | POST | Single gesture prediction |
| `/predict-and-build` | POST | Predict + add to sentence |
| `/sentence` | GET | Get current sentence |
| `/sentence/space` | POST | Add space (complete word) |
| `/sentence/backspace` | POST | Remove last char/word |
| `/sentence/clear` | POST | Clear sentence |
| `/gestures` | GET | List supported gestures |
| `/ws/recognize` | WebSocket | Real-time recognition stream |

**Example Request:**
```bash
curl -X POST http://localhost:8000/predict-image \
  -F "file=@gesture.jpg" \
  -F "language=ASL"
```

**Example Response:**
```json
{
  "label": "Hello",
  "confidence": 0.95,
  "language": "ASL",
  "timestamp": "2025-01-01T00:00:00"
}
```

## ğŸ® How Sentence Building Works

1. **Gesture Recognition**: Each frame is analyzed by the CNN
2. **Confidence Threshold**: Only predictions >70% are considered
3. **Frame Confirmation**: Same gesture must be held for ~15 frames (~3 seconds)
4. **Character Added**: Confirmed character added to current word
5. **Space Gesture**: Completes current word, starts new one
6. **Sentence Complete**: Full sentence ready for text-to-speech

## ğŸ› Troubleshooting

### Backend won't start
```bash
# Ensure you're in python-backend directory
cd python-backend
pip install -r requirements.txt
python server.py
```

### No predictions / always "Error"
- Check if model file exists: `python-backend/models/cnn_model_keras2.h5`
- Without a model, predictions are simulated for testing

### Camera not working
- Allow camera permissions in browser
- Use HTTPS or localhost (required for getUserMedia)
- Close other apps using the camera

### CORS errors
- Backend already has CORS enabled for all origins
- Ensure backend is running on port 8000

## ğŸ“– Original Repository

This project is based on:
**[Sign-Language-Interpreter-using-Deep-Learning](https://github.com/harshbg/Sign-Language-Interpreter-using-Deep-Learning)**

By Harsh Gupta, Siddharth Oza, Ashish Sharma, and Manish Shukla

Created at HackUNT-19, Winner of UNT Hackathon 2019

## ğŸ™ Acknowledgments

- [harshbg](https://github.com/harshbg) for the original interpreter
- TensorFlow/Keras for deep learning framework
- OpenCV for image processing
- FastAPI for modern Python web framework

## ğŸ“„ License

MIT License - See original repository for details

---

**Ready to interpret sign language?** Run `python python-backend/server.py` and open `recognition.html`! ğŸ¤Ÿ
