# SignBridge - Sign Language Interpreter

**Real-time sign language to text & speech interpretation using Deep Learning**

Based on: https://github.com/harshbg/Sign-Language-Interpreter-using-Deep-Learning

![Python](https://img.shields.io/badge/Python-3.8+-blue)
![TensorFlow](https://img.shields.io/badge/TensorFlow-2.15-orange)
![FastAPI](https://img.shields.io/badge/FastAPI-0.109-green)

## ğŸ¯ What This Does

This web application interprets American Sign Language (ASL) gestures in real-time:
1. **Captures** gestures via webcam
2. **Recognizes** letters, numbers, and common words using a trained CNN
3. **Builds sentences** from continuous gesture recognition
4. **Speaks** the interpreted sentence using text-to-speech

## ğŸš€ Quick Start

### Prerequisites
- Python 3.8+
- Modern web browser with camera access

### 1. Install Dependencies

```bash
cd python-backend
pip install -r requirements.txt
```

### 2. Start Backend Server

```bash
# Windows
python server.py

# Or double-click START_BACKEND.bat
```

Server starts at: http://localhost:8000

### 3. Open Frontend

**Option A: XAMPP**
```
Place folder in xampp/htdocs/
Visit: http://localhost/SignLanguage/
```

**Option B: Python HTTP Server**
```bash
python -m http.server 8080
# Visit: http://localhost:8080
```

**Option C: Direct**
```
Open recognition.html in browser
```

### 4. Start Interpreting!

1. Click "Start Interpreter"
2. Allow camera access
3. Make sign language gestures
4. Watch sentences build in real-time!

## ğŸ“Š Supported Gestures (24 Classes)

| Type | Gestures |
|------|----------|
| Letters | A, B, C, D, E, F, G, H, I, K, L, M, N, O, P, Q, R, S, T, U, V, W, X, Y |

**Note:** Sign Language MNIST dataset includes A-Z excluding J and Z (24 classes total)

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   BROWSER (HTML/JS)                          â”‚
â”‚  - Camera capture via getUserMedia                          â”‚
â”‚  - Sends frames every 200ms                                  â”‚
â”‚  - Displays predictions & builds sentences                   â”‚
â”‚  - Text-to-speech output                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚ HTTP POST /predict-and-build
                         â”‚ FormData: {file: blob, language: ASL}
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PYTHON BACKEND (FastAPI)                        â”‚
â”‚  - Image preprocessing (histogram backprojection)           â”‚
â”‚  - Hand segmentation & contour detection                    â”‚
â”‚  - CNN model prediction (TensorFlow/Keras)                  â”‚
â”‚  - Sentence builder (accumulates characters)                â”‚
â”‚  - Returns: {label, confidence, sentence}                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
SignLanguage/
â”œâ”€â”€ index.html                    # Homepage
â”œâ”€â”€ recognition.html              # Main interpreter UI
â”œâ”€â”€ learning.html                 # Learning resources
â”œâ”€â”€ about.html                    # About page
â”œâ”€â”€ START_BACKEND.bat             # Windows launcher
â”œâ”€â”€ python-backend/
â”‚   â”œâ”€â”€ server.py                 # FastAPI server (main logic)
â”‚   â”œâ”€â”€ requirements.txt          # Python dependencies
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ cnn_model_keras2.h5   # Trained model (add this)
â”‚   â”‚   â””â”€â”€ hist                  # Hand histogram (optional)
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ css/
â”‚   â””â”€â”€ style.css
â”œâ”€â”€ js/
â”‚   â””â”€â”€ recognition.js            # Frontend recognition logic
â””â”€â”€ README.md
```

## ğŸ§  The CNN Model

The recognition uses a Convolutional Neural Network trained on Sign Language MNIST:

**Architecture:**
```
Input: 28x28x1 (grayscale)
  â†“
Conv2D(75, 3x3) â†’ BatchNorm â†’ MaxPool(2x2)
  â†“
Conv2D(50, 3x3) â†’ Dropout(0.2) â†’ BatchNorm â†’ MaxPool(2x2)
  â†“
Conv2D(25, 3x3) â†’ BatchNorm â†’ MaxPool(2x2)
  â†“
Flatten â†’ Dense(512) â†’ Dropout(0.3)
  â†“
Output: Softmax(24 classes) â†’ >95% accuracy
```

**Supported Gestures:** A-Z (excluding J and Z) - 24 letter classes

## ğŸ“ Training Your Own Model

**Complete training pipeline included!**

### Quick Start Training:

```bash
cd python-backend/training

# Windows - Easy way:
START_TRAINING.bat

# Or manually:
python train_all.py
```

### Step-by-Step Training:

1. **Set Hand Histogram** (one-time setup):
   ```bash
   python set_hand_histogram.py
   ```
   - Place hand in green squares
   - Press 'C' to capture
   - Press 'S' to save

2. **Capture Gestures** (for each gesture):
   ```bash
   python create_gestures.py
   ```
   - Enter gesture ID (0-43)
   - Enter gesture name (e.g., "A", "Hello")
   - Press 'C' to start capturing
   - Captures 1200 images automatically

3. **Load Images**:
   ```bash
   python load_images.py
   ```
   - Prepares train/validation/test sets

4. **Train Model**:
   ```bash
   python cnn_model_train.py
   ```
   - Trains CNN (takes 30-60 minutes)
   - Saves to `models/cnn_model_keras2.h5`

**See `python-backend/training/TRAINING_GUIDE.md` for detailed instructions.**

### Using Pre-trained Model:

If you have a trained model from the original repository:

1. Copy `cnn_model_keras2.h5` to `python-backend/models/`
2. Copy `hist` to `python-backend/models/` (optional)
3. Start the server - it will automatically load the model

## ğŸ”Œ API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/` | GET | Server status |
| `/health` | GET | Health check with model info |
| `/predict-image` | POST | Single gesture prediction |
| `/predict-and-build` | POST | Predict + add to sentence |
| `/sentence` | GET | Get current sentence |
| `/sentence/space` | POST | Add space (complete word) |
| `/sentence/backspace` | POST | Remove last char/word |
| `/sentence/clear` | POST | Clear sentence |
| `/gestures` | GET | List supported gestures |
| `/ws/recognize` | WebSocket | Real-time recognition stream |

**Example Request:**
```bash
curl -X POST http://localhost:8000/predict-image \
  -F "file=@gesture.jpg" \
  -F "language=ASL"
```

**Example Response:**
```json
{
  "label": "Hello",
  "confidence": 0.95,
  "language": "ASL",
  "timestamp": "2025-01-01T00:00:00"
}
```

## ğŸ® How Sentence Building Works

1. **Gesture Recognition**: Each frame is analyzed by the CNN
2. **Confidence Threshold**: Only predictions >70% are considered
3. **Frame Confirmation**: Same gesture must be held for ~15 frames (~3 seconds)
4. **Character Added**: Confirmed character added to current word
5. **Space Gesture**: Completes current word, starts new one
6. **Sentence Complete**: Full sentence ready for text-to-speech

## ğŸ› Troubleshooting

### Backend won't start
```bash
# Ensure you're in python-backend directory
cd python-backend
pip install -r requirements.txt
python server.py
```

### No predictions / always "Error"
- Check if model file exists: `python-backend/models/cnn_model_keras2.h5`
- Without a model, predictions are simulated for testing

### Camera not working
- Allow camera permissions in browser
- Use HTTPS or localhost (required for getUserMedia)
- Close other apps using the camera

### CORS errors
- Backend already has CORS enabled for all origins
- Ensure backend is running on port 8000

## ğŸ“– Original Repository

This project is based on:
**[Sign-Language-Interpreter-using-Deep-Learning](https://github.com/harshbg/Sign-Language-Interpreter-using-Deep-Learning)**

By Harsh Gupta, Siddharth Oza, Ashish Sharma, and Manish Shukla

Created at HackUNT-19, Winner of UNT Hackathon 2019

## ğŸ™ Acknowledgments

- [harshbg](https://github.com/harshbg) for the original interpreter
- TensorFlow/Keras for deep learning framework
- OpenCV for image processing
- FastAPI for modern Python web framework

## ğŸ“„ License

MIT License - See original repository for details

---

**Ready to interpret sign language?** Run `python python-backend/server.py` and open `recognition.html`! ğŸ¤Ÿ
